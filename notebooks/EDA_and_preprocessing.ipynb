{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e57382",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv\"\n",
    "TEST_URL  = \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â¬‡  Downloading data directly from Source...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_URL)\n",
    "test_df = pd.read_csv(TEST_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98dbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'category': 'intent_name'}, inplace=True)\n",
    "test_df.rename(columns={'category': 'intent_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa20b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data', exist_ok=True)\n",
    "train_df.to_csv('../data/banking77_train.csv', index=False)\n",
    "test_df.to_csv('../data/banking77_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7afa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Success! Data loaded and saved.\")\n",
    "print(f\"   Train Shape: {train_df.shape} (Rows, Cols)\")\n",
    "print(f\"   Test Shape:  {test_df.shape} (Rows, Cols)\")\n",
    "print(f\"   Total Distinct Intents: {train_df['intent_name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ff3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Random Sample of User Queries ---\")\n",
    "sample = train_df[['intent_name', 'text']].sample(5, random_state=42)\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    print(f\" Intent: {row['intent_name']}\")\n",
    "    print(f\"   Query:  \\\"{row['text']}\\\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_counts = train_df['intent_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(y=intent_counts.head(20).index, x=intent_counts.head(20).values, palette='viridis')\n",
    "plt.title(\"Top 20 Most Frequent Support Issues (High Volume)\")\n",
    "plt.xlabel(\"Number of Tickets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = intent_counts.max()\n",
    "min_count = intent_counts.min()\n",
    "print(f\"Most Frequent: {intent_counts.idxmax()} ({max_count})\")\n",
    "print(f\"Least Frequent: {intent_counts.idxmin()} ({min_count})\")\n",
    "print(f\"Imbalance Ratio: 1:{max_count/min_count:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['word_count'] = train_df['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a607653",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_df['word_count'], bins=30, kde=True, color='purple')\n",
    "plt.axvline(train_df['word_count'].mean(), color='red', linestyle='--', label=f\"Mean: {train_df['word_count'].mean():.1f}\")\n",
    "plt.title(\"Distribution of Query Length (How much context do we have?)\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85490f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Insight: The average query is only {train_df['word_count'].mean():.1f} words long.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22914352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de46ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_ngrams(texts, n=2, title=\"Top Bigrams\"):\n",
    "    vec = CountVectorizer(ngram_range=(n, n), stop_words='english').fit(texts)\n",
    "    bag_of_words = vec.transform(texts)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    df_ngram = pd.DataFrame(words_freq, columns=['Ngram', 'Count'])\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(x='Count', y='Ngram', data=df_ngram, palette='Blues_d')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405914b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_a = 'card_arrival'\n",
    "intent_b = 'card_delivery_estimate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ace076",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Comparing: '{intent_a}' vs '{intent_b}'\")\n",
    "plot_top_ngrams(train_df[train_df['intent_name'] == intent_a]['text'], n=2, title=f\"Bigrams: {intent_a}\")\n",
    "plot_top_ngrams(train_df[train_df['intent_name'] == intent_b]['text'], n=2, title=f\"Bigrams: {intent_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_keywords = ['lost', 'stolen', 'fraud', 'hack', 'compromised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a367c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_intents = [i for i in train_df['intent_name'].unique() if any(k in i for k in risk_keywords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49992e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" High-Risk Intents Identified ({len(risk_intents)}):\")\n",
    "print(risk_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_df = train_df[train_df['intent_name'].isin(risk_intents)]\n",
    "print(f\"\\nTotal Risk Samples: {len(risk_df)} ({len(risk_df)/len(train_df)*100:.1f}% of data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd995a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.countplot(y='intent_name', data=risk_df, order=risk_df['intent_name'].value_counts().index, palette='Reds_r')\n",
    "plt.title(\"Volume of Security/Fraud Queries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def senior_cleaning_pipeline(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "   \n",
    "    abbrev_map = {\n",
    "        r\"\\batm\\b\": \"atm\",\n",
    "        r\"\\bpin\\b\": \"pin\",\n",
    "        r\"\\bcard lost\\b\": \"lost card\",\n",
    "        r\"\\bstolen\\b\": \"stolen\"\n",
    "    }\n",
    "    for pattern, replacement in abbrev_map.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "        text = re.sub(r'\\d+', '<NUM>', text)\n",
    "\n",
    "        preserve = \"$%#\"\n",
    "    all_punct = string.punctuation\n",
    "    table = str.maketrans('', '', ''.join(c for c in all_punct if c not in preserve))\n",
    "    text = text.translate(table)\n",
    "\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5bec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"My card #1234 was stolen! I lost $500. It's NOT working at the atm.\"\n",
    "print(f\"Raw Query:      {sample_query}\")\n",
    "print(f\"Senior Cleaned: {senior_cleaning_pipeline(sample_query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Applying Senior Preprocessing Pipeline...\")\n",
    "train_df['text_clean'] = train_df['text'].apply(senior_cleaning_pipeline)\n",
    "test_df['text_clean'] = test_df['text'].apply(senior_cleaning_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50719a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['word_count'] = train_df['text'].str.split().str.len()\n",
    "test_df['word_count'] = test_df['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_pattern = r'lost|stolen|compromised|fraud|unauthorized'\n",
    "train_df['is_high_risk'] = train_df['text_clean'].str.contains(risk_pattern).astype(int)\n",
    "test_df['is_high_risk'] = test_df['text_clean'].str.contains(risk_pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87db3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Processed Data Preview ---\")\n",
    "display(train_df[['text', 'text_clean', 'word_count', 'is_high_risk']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/train_processed.csv', index=False)\n",
    "test_df.to_csv('../data/test_processed.csv', index=False)\n",
    "\n",
    "print(f\"\\n  Files saved to '../data/'.\")\n",
    "print(f\"Risk queries in training set: {train_df['is_high_risk'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    max_features=5000, \n",
    "    stop_words=None   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8091651",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(train_df['text_clean'])\n",
    "X_test_tfidf = tfidf.transform(test_df['text_clean'])\n",
    "\n",
    "print(f\" TF-IDF Matrix Created:\")\n",
    "print(f\"   - Training shape: {X_train_tfidf.shape}\")\n",
    "print(f\"   - Number of unique features (unigrams/bigrams): {len(tfidf.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA and preprocessing done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
